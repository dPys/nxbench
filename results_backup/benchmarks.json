{
    "GraphBenchmark.track_all_pairs_shortest_path_length": {
        "code": "class <locals>:\n    def track_method(self, dataset_name: str, backend: str):\n        \"\"\"Run benchmark and return metrics.\"\"\"\n        metrics = self.do_benchmark(algo_config, dataset_name, backend)\n        logger.debug(f\"Track {algo_name} results: {metrics}\")\n        return metrics\n\nclass GraphBenchmark:\n    def setup(self, dataset_name: str, backend: str) -> bool:\n        \"\"\"Setup for each benchmark iteration.\"\"\"\n        if not self.graphs:\n            self.setup_cache()\n    \n        dataset_name = dataset_name.strip(\"'\")\n    \n        graph_data = self.graphs.get(dataset_name)\n        if graph_data is None:\n            logger.error(f\"Graph for dataset '{dataset_name}' not found in cache.\")\n            return False\n    \n        self.current_graph, metadata = graph_data\n        self.current_backend = backend\n    \n        try:\n            if backend == \"nx_parallel\":\n                import nx_parallel\n            elif backend == \"cugraph\":\n                if not is_cugraph_available():\n                    logger.error(\"cugraph not available\")\n                    return False\n                import cugraph\n    \n                if nx.is_weighted(self.current_graph):\n                    edge_attr = \"weight\"\n                else:\n                    edge_attr = None\n                self.current_graph = cugraph.from_networkx(\n                    self.current_graph, edge_attrs=edge_attr\n                )\n            return True\n        except ImportError as e:\n            logger.error(f\"Backend {backend} not available: {e}\")\n            return False\n        except Exception as e:\n            logger.error(f\"Error setting up backend {backend}: {e}\")\n            return False\n\n    def setup_cache(self):\n        \"\"\"Cache graph data for benchmarks.\"\"\"\n        self.graphs = {}\n        for dataset_name in self.params[0]:\n            dataset_config = next(\n                (\n                    ds\n                    for ds in get_benchmark_config().datasets\n                    if ds.name == dataset_name\n                ),\n                None,\n            )\n            if dataset_config is None:\n                logger.warning(f\"Dataset configuration for '{dataset_name}' not found.\")\n                continue\n            try:\n                graph, metadata = self.data_manager.load_network_sync(dataset_config)\n                self.graphs[dataset_name] = (graph, metadata)\n                logger.debug(\n                    f\"Cached dataset '{dataset_name}' with {graph.number_of_nodes()} nodes\"\n                )\n            except Exception as e:\n                logger.error(f\"Failed to load dataset '{dataset_name}': {e}\")",
        "name": "GraphBenchmark.track_all_pairs_shortest_path_length",
        "param_names": [
            "dataset_name",
            "backend"
        ],
        "params": [
            [
                "'08blocks'",
                "'jazz'",
                "'erdos_renyi_small'",
                "'watts_strogatz_medium'",
                "'powerlaw_cluster'"
            ],
            [
                "'networkx'",
                "'nx_parallel'"
            ]
        ],
        "setup_cache_key": "benchmark:160",
        "type": "track",
        "unit": "seconds+MB",
        "version": "70f95443be68858abd893f4d95f5ea2b3e0d7fafe2f9700ad2f7370945a8011e"
    },
    "benchmark.GraphBenchmark.track_all_pairs_shortest_path_length": {
        "code": "class <locals>:\n    def track_method(self, dataset_name: str, backend: str):\n        \"\"\"Run benchmark and return metrics.\"\"\"\n        metrics = self.do_benchmark(algo_config, dataset_name, backend)\n        logger.debug(f\"Track {algo_name} results: {metrics}\")\n        return metrics\n\nclass GraphBenchmark:\n    def setup(self, dataset_name: str, backend: str) -> bool:\n        \"\"\"Setup for each benchmark iteration.\"\"\"\n        if not self.graphs:\n            self.setup_cache()\n    \n        dataset_name = dataset_name.strip(\"'\")\n    \n        graph_data = self.graphs.get(dataset_name)\n        if graph_data is None:\n            logger.error(f\"Graph for dataset '{dataset_name}' not found in cache.\")\n            return False\n    \n        self.current_graph, metadata = graph_data\n        self.current_backend = backend\n    \n        try:\n            if backend == \"nx_parallel\":\n                import nx_parallel\n            elif backend == \"cugraph\":\n                if not is_cugraph_available():\n                    logger.error(\"cugraph not available\")\n                    return False\n                import cugraph\n    \n                if nx.is_weighted(self.current_graph):\n                    edge_attr = \"weight\"\n                else:\n                    edge_attr = None\n                self.current_graph = cugraph.from_networkx(\n                    self.current_graph, edge_attrs=edge_attr\n                )\n            return True\n        except ImportError as e:\n            logger.error(f\"Backend {backend} not available: {e}\")\n            return False\n        except Exception as e:\n            logger.error(f\"Error setting up backend {backend}: {e}\")\n            return False\n\n    def setup_cache(self):\n        \"\"\"Cache graph data for benchmarks.\"\"\"\n        self.graphs = {}\n        for dataset_name in self.params[0]:\n            dataset_config = next(\n                (\n                    ds\n                    for ds in get_benchmark_config().datasets\n                    if ds.name == dataset_name\n                ),\n                None,\n            )\n            if dataset_config is None:\n                logger.warning(f\"Dataset configuration for '{dataset_name}' not found.\")\n                continue\n            try:\n                graph, metadata = self.data_manager.load_network_sync(dataset_config)\n                self.graphs[dataset_name] = (graph, metadata)\n                logger.debug(\n                    f\"Cached dataset '{dataset_name}' with {graph.number_of_nodes()} nodes\"\n                )\n            except Exception as e:\n                logger.error(f\"Failed to load dataset '{dataset_name}': {e}\")",
        "name": "benchmark.GraphBenchmark.track_all_pairs_shortest_path_length",
        "param_names": [
            "dataset_name",
            "backend"
        ],
        "params": [
            [
                "'08blocks'",
                "'jazz'",
                "'erdos_renyi_small'",
                "'watts_strogatz_medium'",
                "'powerlaw_cluster'"
            ],
            [
                "'networkx'",
                "'nx_parallel'"
            ]
        ],
        "setup_cache_key": "benchmark:160",
        "type": "track",
        "unit": "seconds+MB",
        "version": "70f95443be68858abd893f4d95f5ea2b3e0d7fafe2f9700ad2f7370945a8011e"
    },
    "version": 2
}